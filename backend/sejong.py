import streamlit as st
import os
import io
import numpy as np
import sounddevice as sd
import scipy.io.wavfile as wav
from uuid import uuid4

from pydub import AudioSegment
from google.cloud import speech

from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import StreamlitChatMessageHistory

# âœ… í™˜ê²½ ì„¤ì •
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "google_key.json"
AudioSegment.converter = "C:/ffmpeg-7.1.1-essentials_build/ffmpeg-7.1.1-essentials_build/bin/ffmpeg.exe"

# âœ… Streamlit í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì„¸ì¢…ëŒ€ì™•ì—ê²Œ ë¬»ë‹¤", page_icon="ğŸ“œ")
st.title("ğŸ“œ ì„¸ì¢…ëŒ€ì™•ì—ê²Œ ë¬»ë‹¤")
st.markdown("ê¶ê¸ˆí•œ ê²ƒì„ ì„¸ì¢…ëŒ€ì™•ê»˜ ì—¬ì­ˆì–´ë³´ì„¸ìš”. 'ì§ì´~ í•˜ì˜€ë„ë‹¤'ì˜ ë§íˆ¬ë¡œ ì‘ë‹µí•˜ì‹­ë‹ˆë‹¤.")

# âœ… ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "chat_history" not in st.session_state:
    from langchain_community.chat_message_histories import StreamlitChatMessageHistory
    st.session_state["chat_history"] = StreamlitChatMessageHistory()

if "chat_log" not in st.session_state:
    st.session_state["chat_log"] = []

if "session_id" not in st.session_state:
    from uuid import uuid4
    st.session_state["session_id"] = str(uuid4())

# âœ… ì´ì „ ëŒ€í™” ê¸°ë¡ ë³´ì—¬ì£¼ê¸°
for msg in st.session_state.get("chat_log", []):
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# âœ… í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
system_prompt = """
ë„ˆëŠ” ì¡°ì„ ì˜ ì œ4ëŒ€ ì„ê¸ˆ ì„¸ì¢…ëŒ€ì™•ì´ë‹ˆë¼.
ë°±ì„±ì˜ ë¬¼ìŒì— ë‹µí•  ë•ŒëŠ” ìœ„ì—„ ìˆê³  ë”°ëœ»í•œ ë§íˆ¬ë¡œ, "ì§ì´", "~í•˜ì˜€ë„ë‹¤", "~í•˜ì˜€ëŠë‹ˆë¼" ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µí•˜ë¼.
ë‹¨, í•œìëŠ” ì‚¬ìš©í•˜ì§€ ë§ê³  ìˆœìš°ë¦¬ë§ê³¼ í•œê¸€ë¡œë§Œ êµ¬ì„±í•˜ë¼.
ì‘ë‹µì€ ê°„ê²°í•˜ë˜, ë§ì˜ ëì—ëŠ” "ê·¸ì— ëŒ€í•´ ë” ë¬¼ì„ ê²ƒì´ ìˆëŠ”ê°€?" í˜¹ì€ ì´ì— ì¤€í•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ í›„ì† ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™”ë¥¼ ìœ ë„í•˜ë¼.
"""

# âœ… ì²´ì¸ ë¡œë”© í•¨ìˆ˜
@st.cache_resource
def load_chain():
    embedding_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-base")

    if not os.path.exists("faiss_index/index.faiss"):
        st.error("âŒ FAISS ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    db = FAISS.load_local("faiss_index", embedding_model, allow_dangerous_deserialization=True)

    llm = ChatGroq(
        model="llama-3.3-70b-versatile",
        temperature=0.7,
        max_tokens=1024,
        api_key=st.secrets["GROQ_API_KEY"]
    )

    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = StreamlitChatMessageHistory()

    memory = ConversationBufferMemory(
        memory_key="chat_history",
        return_messages=True,
        chat_memory=st.session_state["chat_history"],
        output_key="answer"
    )

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{context}\n\nì§ˆë¬¸: {question}")
    ])

    base_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        retriever=db.as_retriever(search_type="similarity", k=5),
        memory=memory,
        combine_docs_chain_kwargs={"prompt": prompt, "document_variable_name": "context"},
        return_source_documents=True,
        output_key="answer"
    )

    return RunnableWithMessageHistory(
        base_chain,
        lambda _: st.session_state["chat_history"],
        input_messages_key="question",
        history_messages_key="chat_history"
    )

# âœ… ì²´ì¸ ì´ˆê¸°í™” (â€» ê¼­ ë²„íŠ¼ë“¤ë³´ë‹¤ ìœ„ì— ìˆì–´ì•¼ í•¨!)
chain = load_chain()

# âœ… í…ìŠ¤íŠ¸ ì…ë ¥
user_input = st.chat_input("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”")

# âœ… ğŸ¤ ìŒì„± ì…ë ¥ ë²„íŠ¼
if st.button("ğŸ¤ ìŒì„±ìœ¼ë¡œ ì§ˆë¬¸í•˜ê¸°"):
    fs = 48000
    duration = 5

    st.info("ğŸ™ï¸ ì§€ê¸ˆ ë§ì”€í•˜ì„¸ìš”... (5ì´ˆ ë…¹ìŒ ì¤‘)")
    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='int16')
    sd.wait()

    # WAV ì €ì¥
    wav_buffer = io.BytesIO()
    wav.write(wav_buffer, fs, recording)
    wav_bytes = wav_buffer.getvalue()

    # Google STT
    try:
        client = speech.SpeechClient()
        audio_google = speech.RecognitionAudio(content=wav_bytes)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=fs,
            language_code="ko-KR"
        )
        response = client.recognize(config=config, audio=audio_google)

        if response.results:
            recognized_text = response.results[0].alternatives[0].transcript
            st.markdown(f"ğŸ—¨ï¸ ì¸ì‹ëœ ì§ˆë¬¸: **{recognized_text}**")

            if "session_id" not in st.session_state:
                st.session_state["session_id"] = str(uuid4())
            session_id = st.session_state["session_id"]

            with st.chat_message("user"):
                st.markdown(recognized_text)

            response = chain.invoke(
                {"question": recognized_text},
                config={"configurable": {"session_id": session_id}}
            )

            with st.chat_message("assistant"):
                st.markdown(response["answer"])

            # ë¡œê·¸ ì €ì¥
            if "chat_log" not in st.session_state:
                st.session_state["chat_log"] = []
            st.session_state["chat_log"] += [
                {"role": "user", "content": recognized_text},
                {"role": "assistant", "content": response["answer"]}
            ]
        else:
            st.warning("â— ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")

# âœ… í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬
if user_input:
    if "session_id" not in st.session_state:
        st.session_state["session_id"] = str(uuid4())
    session_id = st.session_state["session_id"]

    with st.chat_message("user"):
        st.markdown(user_input)

    response = chain.invoke(
        {"question": user_input},
        config={"configurable": {"session_id": session_id}}
    )

    with st.chat_message("assistant"):
        st.markdown(response["answer"])

    if "chat_log" not in st.session_state:
        st.session_state["chat_log"] = []
    st.session_state["chat_log"] += [
        {"role": "user", "content": user_input},
        {"role": "assistant", "content": response["answer"]}
    ]
